{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T05:06:30.633843Z",
     "start_time": "2022-08-11T05:06:21.933678Z"
    }
   },
   "outputs": [],
   "source": [
    "## get RNA sequence fasta files and separate RNA monomer from the complex for network features calculation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import cmath\n",
    "\n",
    "rna_seq = {}\n",
    "f_g = glob.glob('pdb/*.pdb')\n",
    "for f_i in f_g:\n",
    "    rnaname = os.path.basename(f_i)[:4]\n",
    "    aanub = 100000\n",
    "    seq = ''\n",
    "    with open(\"pdb/%s.pdb\"%(rnaname),\"r\") as f_r:\n",
    "        lines = f_r.readlines()\n",
    "        for line in lines:\n",
    "            if line[0:4] == \"ATOM\":\n",
    "                if aanub != line[22:26]:\n",
    "                    seq = seq+ line[19:20]\n",
    "                aanub = line[22:26]\n",
    "                fw1 = open('graph_pdb/%s.pdb'%rnaname, 'a+') \n",
    "                fw1.write(line)\n",
    "                fw2 = open('fasta/%s.fasta'%rnaname, 'w')\n",
    "                fw2.write('>'+rnaname+'\\n')\n",
    "                fw2.write(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T05:35:31.449662Z",
     "start_time": "2022-08-11T05:35:30.428941Z"
    }
   },
   "outputs": [],
   "source": [
    "#######RNA features integration                        ---- written by kaili\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "nucle_type ={'A':[1,0,0,0],\n",
    "            'U':[0,1,0,0],\n",
    "            'C':[0,0,1,0],\n",
    "            'G':[0,0,0,1]\n",
    "}\n",
    "mass ={'A':507.18,\n",
    "       'U':484.141,\n",
    "       'C':483.156,\n",
    "       'G':523.18   \n",
    "}\n",
    "PKa ={'A':3.5,\n",
    "      'U':9.2,\n",
    "      'C':4.2,\n",
    "      'G':10.8  \n",
    "}\n",
    "rna_features=[]\n",
    "nucle_4=[]\n",
    "mass_normal=[]\n",
    "pka_normal=[]\n",
    "clon=[]\n",
    "deg=[]\n",
    "conserv_normal=[]\n",
    "asa_normal=[]\n",
    "f_cont = glob.glob(\"./pdb/*.pdb\")\n",
    "for fi in f_cont:\n",
    "    rnaname = os.path.basename(fi)[:4]\n",
    "    nucle_list=[]\n",
    "    mass_list=[]\n",
    "    pka_list=[]\n",
    "    with open(r\"./fasta/%s.fasta\"%(rnaname),\"r\") as f1:\n",
    "        for line in f1:\n",
    "            if line[0] != \">\":\n",
    "                seq = line.strip()\n",
    "                for nucle in seq:\n",
    "                    nucle_onehot=nucle_type[nucle]\n",
    "                    ma=float(mass[nucle])/523.18\n",
    "                    pk=float(PKa[nucle])/10.8\n",
    "                    nucle_list.append(nucle_onehot)\n",
    "                    mass_list.append(ma)\n",
    "                    pka_list.append(pk)\n",
    "                nucle_4.append(nucle_list)\n",
    "                mass_normal.append(mass_list)\n",
    "                pka_normal.append(pka_list)\n",
    "    with open(r'./features/closeness/Outputs/%s_closeness.txt'%(rnaname), 'r') as f2:\n",
    "        cl_list=[]\n",
    "        for line in f2:\n",
    "            cl = line.strip()\n",
    "            cl_list.append(float(cl))      \n",
    "        clon.append(cl_list)\n",
    "    with open(r'./features/degree/Outputs/%s_degree.txt'%(rnaname), 'r') as f3:\n",
    "        for line in f3:\n",
    "            de = line[:-1].strip().split(',')\n",
    "        deg.append(de)    \n",
    "    with open(r'./features/conservation/%s/consurf.grades'%(rnaname), 'r') as f4:\n",
    "        conser_list=[]\n",
    "        for _ in range(15):\n",
    "            next(f4)\n",
    "        for line in f4:\n",
    "            if line[31:32]== '':\n",
    "                break\n",
    "            else:\n",
    "                conser =line[31:32]\n",
    "                conser_list.append(float(conser)/9)\n",
    "        conserv_normal.append(conser_list)\n",
    "    with open(r'./features/ASA/%s.txt'%(rnaname), 'r') as f5:\n",
    "#         print(rna_name)\n",
    "        asa_list=[]\n",
    "        for _ in range(1):\n",
    "            next(f5)\n",
    "        for line in f5:\n",
    "            asa_value = line.strip().split('\t')[2]\n",
    "            asa_list.append(float(asa_value)/400)  # maximum value of all the data\n",
    "        asa_normal.append(asa_list)       \n",
    "data_pack = []\n",
    "for i in range(0,1): # files traverse\n",
    "    data_pack.append([])\n",
    "    for j in range(0,len(nucle_4[i])):\n",
    "        temp = []\n",
    "        temp += nucle_4[i][j]\n",
    "        temp.append(clon[i][j])\n",
    "        temp.append(int(deg[i][j])/24.0)  # maximum value of all the data\n",
    "        temp.append(conserv_normal[i][j])\n",
    "        temp.append(asa_normal[i][j])\n",
    "        temp.append(mass_normal[i][j])\n",
    "        temp.append(pka_normal[i][j])\n",
    "        data_pack[i].append(temp)\n",
    "pickle.dump(data_pack,Path('./features/integration/demo.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T05:35:43.529667Z",
     "start_time": "2022-08-11T05:35:43.294980Z"
    }
   },
   "outputs": [],
   "source": [
    "#######RNA motif features integration\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "nucle_type ={'A':[1,0,0,0],\n",
    "            'U':[0,1,0,0],\n",
    "            'C':[0,0,1,0],\n",
    "            'G':[0,0,0,1]\n",
    "}\n",
    "mass ={'A':507.18,\n",
    "       'U':484.141,\n",
    "       'C':483.156,\n",
    "       'G':523.18   \n",
    "}\n",
    "PKa ={'A':3.5,\n",
    "      'U':9.2,\n",
    "      'C':4.2,\n",
    "      'G':10.8  \n",
    "}\n",
    "rna_features=[]\n",
    "nucle_4=[]\n",
    "mass_normal=[]\n",
    "pka_normal=[]\n",
    "clon=[]\n",
    "deg=[]\n",
    "conserv_normal=[]\n",
    "asa_normal=[]\n",
    "f_cont = glob.glob(\"./pdb/*.pdb\")\n",
    "for fi in f_cont:\n",
    "    rnaname = os.path.basename(fi)[:4]\n",
    "    nucle_list=[]\n",
    "    mass_list=[]\n",
    "    pka_list=[]\n",
    "    with open(r\"./fasta/%s.fasta\"%(rnaname),\"r\") as f1:\n",
    "        for line in f1:\n",
    "            if line[0] != \">\":\n",
    "                seq = line.strip()\n",
    "                for nucle in seq:\n",
    "                    nucle_onehot=nucle_type[nucle]\n",
    "                    ma=float(mass[nucle])/523.18\n",
    "                    pk=float(PKa[nucle])/10.8\n",
    "                    nucle_list.append(nucle_onehot)\n",
    "                    mass_list.append(ma)\n",
    "                    pka_list.append(pk)\n",
    "                nucle_4.append(nucle_list)\n",
    "                mass_normal.append(mass_list)\n",
    "                pka_normal.append(pka_list)\n",
    "    with open(r'./features/closeness/Outputs/%s_closeness.txt'%(rnaname), 'r') as f2:\n",
    "        cl_list=[]\n",
    "        for line in f2:\n",
    "            cl = line.strip()\n",
    "            cl_list.append(float(cl))      \n",
    "        clon.append(cl_list)\n",
    "    with open(r'./features/degree/Outputs/%s_degree.txt'%(rnaname), 'r') as f3:\n",
    "        for line in f3:\n",
    "            de = line[:-1].strip().split(',')\n",
    "        deg.append(de)    \n",
    "    with open(r'./features/conservation/%s/consurf.grades'%(rnaname), 'r') as f4:\n",
    "        conser_list=[]\n",
    "        for _ in range(15):\n",
    "            next(f4)\n",
    "        for line in f4:\n",
    "            if line[31:32]== '':\n",
    "                break\n",
    "            else:\n",
    "                conser =line[31:32]\n",
    "                conser_list.append(float(conser)/9)\n",
    "        conserv_normal.append(conser_list)\n",
    "    with open(r'./features/ASA/%s.txt'%(rnaname), 'r') as f5:\n",
    "        asa_list=[]\n",
    "        for _ in range(1):\n",
    "            next(f5)\n",
    "        for line in f5:\n",
    "            asa_value = line.strip().split('\t')[2]\n",
    "            asa_list.append(float(asa_value)/400)  # maximum value of all the data\n",
    "        asa_normal.append(asa_list)       \n",
    "data_pack = []\n",
    "for i in range(0,1):   # files traverse\n",
    "    data_pack.append([])\n",
    "    for j in range(0,len(nucle_4[i])):\n",
    "        temp = []\n",
    "        temp += nucle_4[i][j]\n",
    "        temp.append(clon[i][j])\n",
    "        temp.append(int(deg[i][j])/24.0)  # maximum value of all the data\n",
    "        temp.append(conserv_normal[i][j])\n",
    "        temp.append(asa_normal[i][j])\n",
    "        temp.append(mass_normal[i][j])\n",
    "        temp.append(pka_normal[i][j])\n",
    "        data_pack[i].append(temp)\n",
    "a = []\n",
    "for m in range(0,1):\n",
    "    i=0\n",
    "    for n in range(0,len(data_pack[m])):\n",
    "        le=10\n",
    "        lis=[0]*le\n",
    "        motif_list=[]\n",
    "        if n-1 <0:\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(data_pack[m][n])\n",
    "            motif_list.append(data_pack[m][n+1])\n",
    "            motif_list.append(data_pack[m][n+2])\n",
    "            motif_list.append(data_pack[m][n+3])\n",
    "            motif_list.append(data_pack[m][n+4])\n",
    "            motif_list.append(data_pack[m][n+5])\n",
    "        elif n-1>=0 and n-2 <0:\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(data_pack[m][n-1])\n",
    "            motif_list.append(data_pack[m][n])\n",
    "            motif_list.append(data_pack[m][n+1])\n",
    "            motif_list.append(data_pack[m][n+2])\n",
    "            motif_list.append(data_pack[m][n+3])\n",
    "            motif_list.append(data_pack[m][n+4])\n",
    "            motif_list.append(data_pack[m][n+5])\n",
    "        elif n-1>=0 and n-2>=0 and n-3 <0:\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(data_pack[m][n-2])\n",
    "            motif_list.append(data_pack[m][n-1])\n",
    "            motif_list.append(data_pack[m][n])\n",
    "            motif_list.append(data_pack[m][n+1])\n",
    "            motif_list.append(data_pack[m][n+2])\n",
    "            motif_list.append(data_pack[m][n+3])\n",
    "            motif_list.append(data_pack[m][n+4])\n",
    "            motif_list.append(data_pack[m][n+5])\n",
    "        elif n-1>=0 and n-2>=0 and n-3 >=0 and n-4 <0:\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(data_pack[m][n-3])\n",
    "            motif_list.append(data_pack[m][n-2])\n",
    "            motif_list.append(data_pack[m][n-1])\n",
    "            motif_list.append(data_pack[m][n])\n",
    "            motif_list.append(data_pack[m][n+1])\n",
    "            motif_list.append(data_pack[m][n+2])\n",
    "            motif_list.append(data_pack[m][n+3])\n",
    "            motif_list.append(data_pack[m][n+4])\n",
    "            motif_list.append(data_pack[m][n+5])\n",
    "        elif n-1>=0 and n-2>=0 and n-3 >=0 and n-4 >=0 and n-5<0:\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(data_pack[m][n-4])\n",
    "            motif_list.append(data_pack[m][n-3])\n",
    "            motif_list.append(data_pack[m][n-2])\n",
    "            motif_list.append(data_pack[m][n-1])\n",
    "            motif_list.append(data_pack[m][n])\n",
    "            motif_list.append(data_pack[m][n+1])\n",
    "            motif_list.append(data_pack[m][n+2])\n",
    "            motif_list.append(data_pack[m][n+3])\n",
    "            motif_list.append(data_pack[m][n+4])\n",
    "            motif_list.append(data_pack[m][n+5])\n",
    "        elif n+1 == len(data_pack[m]):\n",
    "            motif_list.append(data_pack[m][n-5])\n",
    "            motif_list.append(data_pack[m][n-4])\n",
    "            motif_list.append(data_pack[m][n-3])\n",
    "            motif_list.append(data_pack[m][n-2])\n",
    "            motif_list.append(data_pack[m][n-1])\n",
    "            motif_list.append(data_pack[m][n])\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "        elif n+1 <= len(data_pack[m]) and n+2 == len(data_pack[m]):\n",
    "            motif_list.append(data_pack[m][n-5])\n",
    "            motif_list.append(data_pack[m][n-4])\n",
    "            motif_list.append(data_pack[m][n-3])\n",
    "            motif_list.append(data_pack[m][n-2])\n",
    "            motif_list.append(data_pack[m][n-1])\n",
    "            motif_list.append(data_pack[m][n])\n",
    "            motif_list.append(data_pack[m][n+1])\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "        elif n+2 <= len(data_pack[m]) and n+3 == len(data_pack[m]):\n",
    "            motif_list.append(data_pack[m][n-5])\n",
    "            motif_list.append(data_pack[m][n-4])\n",
    "            motif_list.append(data_pack[m][n-3])\n",
    "            motif_list.append(data_pack[m][n-2])\n",
    "            motif_list.append(data_pack[m][n-1])\n",
    "            motif_list.append(data_pack[m][n])\n",
    "            motif_list.append(data_pack[m][n+1])\n",
    "            motif_list.append(data_pack[m][n+2])\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "        elif n+3 <= len(data_pack[m]) and n+4 == len(data_pack[m]):\n",
    "            motif_list.append(data_pack[m][n-5])\n",
    "            motif_list.append(data_pack[m][n-4])\n",
    "            motif_list.append(data_pack[m][n-3])\n",
    "            motif_list.append(data_pack[m][n-2])\n",
    "            motif_list.append(data_pack[m][n-1])\n",
    "            motif_list.append(data_pack[m][n])\n",
    "            motif_list.append(data_pack[m][n+1])\n",
    "            motif_list.append(data_pack[m][n+2])\n",
    "            motif_list.append(data_pack[m][n+3])\n",
    "            motif_list.append(lis)\n",
    "            motif_list.append(lis)\n",
    "        elif n+4 <= len(data_pack[m]) and n+5 == len(data_pack[m]):\n",
    "            motif_list.append(data_pack[m][n-5])\n",
    "            motif_list.append(data_pack[m][n-4])\n",
    "            motif_list.append(data_pack[m][n-3])\n",
    "            motif_list.append(data_pack[m][n-2])\n",
    "            motif_list.append(data_pack[m][n-1])\n",
    "            motif_list.append(data_pack[m][n])\n",
    "            motif_list.append(data_pack[m][n+1])\n",
    "            motif_list.append(data_pack[m][n+2])\n",
    "            motif_list.append(data_pack[m][n+3])\n",
    "            motif_list.append(data_pack[m][n+4])\n",
    "            motif_list.append(lis)\n",
    "        else:\n",
    "            motif_list.append(data_pack[m][n-5])\n",
    "            motif_list.append(data_pack[m][n-4])\n",
    "            motif_list.append(data_pack[m][n-3])\n",
    "            motif_list.append(data_pack[m][n-2])\n",
    "            motif_list.append(data_pack[m][n-1])\n",
    "            motif_list.append(data_pack[m][n])\n",
    "            motif_list.append(data_pack[m][n+1])\n",
    "            motif_list.append(data_pack[m][n+2])\n",
    "            motif_list.append(data_pack[m][n+3])\n",
    "            motif_list.append(data_pack[m][n+4])\n",
    "            motif_list.append(data_pack[m][n+5])\n",
    "        a.append(np.array(motif_list))\n",
    "pickle.dump(a,Path('./features/integration/demo_mot11.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T05:36:28.855311Z",
     "start_time": "2022-08-11T05:36:28.766977Z"
    }
   },
   "outputs": [],
   "source": [
    "### get RNA index file\n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "pdbid = []\n",
    "seq_indx = []\n",
    "len_list = []\n",
    "seq_nums_list = []\n",
    "name_list = []\n",
    "length_list = []\n",
    "idx_list = []\n",
    "idx = -1\n",
    "na = -1\n",
    "seq_nums = -1\n",
    "f_cont = glob.glob(\"./fasta/*.fasta\")\n",
    "for fi in f_cont:\n",
    "    rnaname = os.path.basename(fi)[:4]\n",
    "    pdbid.append(rnaname)\n",
    "    with open(r\"./fasta/%s.fasta\"%(rnaname),\"r\") as f1:\n",
    "        for line in f1:\n",
    "            if line[0] != \">\":\n",
    "                seq = line.strip()\n",
    "                len_list.append(str(len(seq)))\n",
    "for i in len_list:\n",
    "    na += 1\n",
    "    nucleo_id = -1\n",
    "    seq_nums += 1\n",
    "    for j in range(int(i)):\n",
    "        temp= []\n",
    "        idx += 1\n",
    "        nucleo_id += 1\n",
    "        idx_list.append(idx)\n",
    "        seq_numbs = seq_nums\n",
    "        name = pdbid[na]\n",
    "        length = len_list[na]\n",
    "        seq_nums_list.append(seq_numbs)\n",
    "        name_list.append(name)\n",
    "        length_list.append(length) \n",
    "        temp.append(idx)\n",
    "        temp.append(nucleo_id)\n",
    "        temp.append(seq_numbs)\n",
    "        temp.append(name)\n",
    "        temp.append(length)\n",
    "        seq_indx.append(tuple(temp))\n",
    "pickle.dump(seq_indx,Path('./features/integration/demo_index_all.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T05:36:48.866035Z",
     "start_time": "2022-08-11T05:36:48.855465Z"
    }
   },
   "outputs": [],
   "source": [
    "# the index of each motif\n",
    "train_val = []\n",
    "for ii in range(29):  # the number of all the nucleotides\n",
    "    train_val.append(ii)\n",
    "pickle.dump(train_val,Path('./features/integration/demo_index.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T05:40:43.117958Z",
     "start_time": "2022-08-11T05:40:43.098158Z"
    }
   },
   "outputs": [],
   "source": [
    "alllab = []\n",
    "f_cont = glob.glob(\"./features/label/*_labels.csv\")\n",
    "for fi in f_cont:\n",
    "    rnaname = os.path.basename(fi)[:4]\n",
    "    siglab = []\n",
    "    with open(r\"./features/label/%s_labels.csv\"%(rnaname),\"r\") as f1:\n",
    "        for line in f1:\n",
    "            lab = line.strip().split(\",\")[1]\n",
    "            siglab.append(lab)\n",
    "    alllab.append(siglab)\n",
    "pickle.dump(alllab,Path('./features/integration/demo_label.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLBind",
   "language": "python",
   "name": "rlbind_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
